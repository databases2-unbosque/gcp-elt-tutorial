{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from concurrent.futures import TimeoutError\n",
    "\n",
    "from google.cloud import pubsub_v1\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_FORMAT = '%a %b %d %H:%M:%S +0000 %Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/_modules/nltk/tokenize/casual.html\n",
    "tokenizer = TweetTokenizer(preserve_case = False, reduce_len = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to be called when a new message is received\n",
    "def callback(message):\n",
    "    data = json.loads(message.data.decode('utf-8'))\n",
    "    \n",
    "    # Extracting entities\n",
    "    entities = extract_entities(data['full_text'])\n",
    "    \n",
    "    # Appending datetime of creation\n",
    "    created_at = datetime.strptime(data['created_at'], DATE_FORMAT).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    entities = [ dict(e, **{ 'created_at': created_at }) for e in entities ]\n",
    "    print(entities)\n",
    "    \n",
    "    # Loading entity records to BigQuery\n",
    "    if len(entities) > 0:\n",
    "        errors = bigquery_client.insert_rows_json(TABLE, entities)\n",
    "        if not (errors == []):\n",
    "            print(\"Encountered errors while inserting rows into BigQuery: {}\".format(errors))\n",
    "    \n",
    "    # ACK message\n",
    "    message.ack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for analyzing the tweet and extract hashtags and mentions\n",
    "def extract_entities(text):\n",
    "    hashtags = [t for t in tokenizer.tokenize(text) if (t.startswith('#') and len(t) > 1)]\n",
    "    mentions = [t for t in tokenizer.tokenize(text) if (t.startswith('@') and len(t) > 1)]\n",
    "    \n",
    "    return [ { 'entity': 'hashtag', 'value': h } for h in hashtags ] + [ { 'entity': 'mention', 'value': m } for m in mentions ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Google Cloud Pub/Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'unbosque'\n",
    "SUBSCRIPTION = 'new-tweet-notify-sub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Pub/Sub subscriber client\n",
    "subscriber_client = pubsub_v1.SubscriberClient.from_service_account_json('unbosque.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the subscription path\n",
    "subscription_path = subscriber_client.subscription_path(PROJECT_ID, SUBSCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the streaming pull for the subscription\n",
    "streaming_pull_future = subscriber_client.subscribe(subscription_path, callback = callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Google Cloud BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE = 'unbosque.trends.history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the BigQuery client\n",
    "bigquery_client = bigquery.Client.from_service_account_json('unbosque.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listening for new messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with subscriber_client:\n",
    "    try:\n",
    "        # Streaming data\n",
    "        streaming_pull_future.result()\n",
    "    except TimeoutError:\n",
    "        streaming_pull_future.cancel()  # Trigger the shutdown\n",
    "        streaming_pull_future.result()  # Block until the shutdown is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
